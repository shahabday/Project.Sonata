{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d975ce38",
   "metadata": {},
   "source": [
    "# üéµ Sonata Generation with AI (GPT-Based Model)\n",
    "## **Project Goal**\n",
    "Create a **GPT-like model** that generates a **classical sonata** based on a few given notes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61972e2",
   "metadata": {},
   "source": [
    "## **1Ô∏è‚É£ Convert User Input Notes into Machine-Readable Format**\n",
    "‚úÖ **Goal:** Convert user notes (e.g., C4, D4, E4) into a format the model understands.\n",
    "\n",
    "#### **Action Steps:**\n",
    "- Choose a representation:\n",
    "  - **MIDI Events** (`NOTE_ON`, `NOTE_OFF`, `TIME_SHIFT`)\n",
    "  - **ABC Notation** (human-readable)\n",
    "- Implement a function to convert **musical notes ‚Üí tokens**.\n",
    "\n",
    "üîπ **Example:**\n",
    "```\n",
    "User Input: [\"C4\", \"D4\", \"E4\"]\n",
    "Machine Input: \"NOTE_ON_60 TIME_SHIFT_200 NOTE_OFF_60 NOTE_ON_64\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2af671",
   "metadata": {},
   "source": [
    "## **2Ô∏è‚É£ Select & Download a Dataset**\n",
    "‚úÖ **Goal:** Use a high-quality dataset of classical music.\n",
    "\n",
    "#### **Action Steps:**\n",
    "1. **Use MAESTRO dataset** (best for classical music).\n",
    "2. Download the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9056eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0.csv -O maestro_metadata.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7774ba4c",
   "metadata": {},
   "source": [
    "## **3Ô∏è‚É£ Tokenize MIDI for GPT**\n",
    "‚úÖ **Goal:** Convert MIDI files into **text-like tokens**.\n",
    "\n",
    "üîπ **Use `miditok` (recommended)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352cb3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install miditok miditoolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cf5270",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import miditok\n",
    "import miditoolkit\n",
    "\n",
    "# Load MIDI and tokenize\n",
    "midi_obj = miditoolkit.MidiFile(\"your_midi_file.mid\")\n",
    "tokenizer = miditok.TSD()\n",
    "tokens = tokenizer.midi_to_tokens(midi_obj)\n",
    "\n",
    "print(tokens)  # Example: [\"NOTE_ON_60\", \"TIME_SHIFT_200\", \"NOTE_OFF_60\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b900a6",
   "metadata": {},
   "source": [
    "## **4Ô∏è‚É£ Select a GPT Model for Colab (A100 GPU)**\n",
    "‚úÖ **Goal:** Choose a **trainable** model.\n",
    "\n",
    "| **Model**        | **Best For** | **VRAM** |\n",
    "|-----------------|-------------|----------|\n",
    "| GPT-2 Small     | Fast training | 4GB |\n",
    "| GPT-2 Medium    | More expressive | 8GB |\n",
    "| GPT-2 Large     | High-quality | 16GB |\n",
    "| TransformerXL   | Longer sequences | 8GB |\n",
    "\n",
    "üîπ **Start with GPT-2 Small for quick testing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51b2e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load model & tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Add MIDI-specific tokens\n",
    "new_tokens = [f\"NOTE_ON_{i}\" for i in range(128)] + [\"TIME_SHIFT_200\"]\n",
    "tokenizer.add_tokens(new_tokens)\n",
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a65a360",
   "metadata": {},
   "source": [
    "## **5Ô∏è‚É£ Prepare Dataset for Training**\n",
    "‚úÖ **Goal:** Convert **MIDI to tokenized sequences**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81104956",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MIDIDataset(Dataset):\n",
    "    def __init__(self, token_sequences, seq_length=512):\n",
    "        self.token_sequences = token_sequences\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.token_sequences[idx]\n",
    "        return torch.tensor(sequence[:self.seq_length], dtype=torch.long)\n",
    "\n",
    "# Convert dataset\n",
    "dataset = MIDIDataset(token_sequences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75381839",
   "metadata": {},
   "source": [
    "## **6Ô∏è‚É£ Train the Model**\n",
    "‚úÖ **Goal:** Train GPT-2 on the MIDI token dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./midi-gpt\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33714578",
   "metadata": {},
   "source": [
    "## **7Ô∏è‚É£ Generate & Analyze the Output**\n",
    "‚úÖ **Goal:** Generate a **sonata** from user-provided notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fd98d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_midi(prompt_tokens, max_length=512):\n",
    "    input_ids = torch.tensor([prompt_tokens]).to(model.device)\n",
    "    output_ids = model.generate(input_ids, max_length=max_length, do_sample=True, temperature=0.9)\n",
    "    return tokenizer.decode(output_ids[0])\n",
    "\n",
    "# Example generation\n",
    "prompt_tokens = tokenizer.encode(\"NOTE_ON_60 TIME_SHIFT_200 NOTE_ON_64\")\n",
    "generated_midi = generate_midi(prompt_tokens)\n",
    "print(\"Generated MIDI Tokens:\", generated_midi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2161cb7",
   "metadata": {},
   "source": [
    "## **8Ô∏è‚É£ Convert Generated Tokens to MIDI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238dc41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generated_tokens = generated_midi.split()\n",
    "midi_obj = tokenizer.tokens_to_midi(generated_tokens)\n",
    "\n",
    "# Save as MIDI file\n",
    "midi_obj.dump(\"generated_sonata.mid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5885a79f",
   "metadata": {},
   "source": [
    "## **üöÄ Summary**\n",
    "| Step | Task | Tools |\n",
    "|------|------|-------|\n",
    "| **1** | Convert user input notes | `miditok`, manual encoding |\n",
    "| **2** | Select & download dataset | `maestro` dataset |\n",
    "| **3** | Tokenize MIDI | `miditok` |\n",
    "| **4** | Select a GPT model | `GPT-2 Small` |\n",
    "| **5** | Prepare dataset | Convert MIDI to sequences |\n",
    "| **6** | Train model | `transformers.Trainer()` |\n",
    "| **7** | Generate sonata | Convert tokens ‚Üí MIDI |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39993856",
   "metadata": {},
   "source": [
    "## **üéµ Next Steps**\n",
    "1Ô∏è‚É£ **Run the preprocessing scripts in Google Colab.**\n",
    "2Ô∏è‚É£ **Test different training configurations.**\n",
    "3Ô∏è‚É£ **Improve generation quality by tweaking hyperparameters.**\n",
    "\n",
    "üî• **Would you like detailed Colab notebooks for each step?** üöÄüéº"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
